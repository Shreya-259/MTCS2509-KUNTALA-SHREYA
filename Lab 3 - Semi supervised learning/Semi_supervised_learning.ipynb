{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAoMmI57S03R",
        "outputId": "0d0bf3cd-34a2-4d73-9d14-dac6b6cc8c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1: Accuracy on unlabeled (debug only): 93.30%\n",
            "\n",
            "Iteration 2: Accuracy on unlabeled (debug only): 93.30%\n",
            "Label change since last iteration: 0.00%\n",
            "\n",
            "Change below threshold, stopping self-training.\n",
            "\n",
            "Testing:\n",
            "Accuracy on test data: 93.17%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.sparse import vstack\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# --- Load data ---\n",
        "categories = ['rec.sport.baseball', 'sci.space', 'talk.politics.mideast']\n",
        "newsgroups = fetch_20newsgroups(subset='all', shuffle=True, categories=categories)\n",
        "\n",
        "# --- Helper function ---\n",
        "def extract_body(text):\n",
        "    parts = re.split(r'\\n\\s*\\n', text, maxsplit=1)\n",
        "    return parts[1] if len(parts) > 1 else text\n",
        "\n",
        "cleaned_data = [extract_body(doc) for doc in newsgroups.data]\n",
        "labels = newsgroups.target\n",
        "\n",
        "# --- Split data ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cleaned_data, labels, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# Split training data into labeled and unlabeled\n",
        "X_train_labeled, X_train_unlabeled, y_train_labeled, y_dummy = train_test_split(\n",
        "    X_train, y_train, test_size=0.75, random_state=42\n",
        ")\n",
        "\n",
        "# --- Vectorization ---\n",
        "count_vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X_train_labeled_vec = count_vectorizer.fit_transform(X_train_labeled)\n",
        "X_train_unlabeled_vec = count_vectorizer.transform(X_train_unlabeled)\n",
        "X_test_vec = count_vectorizer.transform(X_test)\n",
        "\n",
        "# --- Initial model ---\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "# classifier = MultinomialNB()\n",
        "\n",
        "classifier.fit(X_train_labeled_vec, y_train_labeled)\n",
        "\n",
        "# --- Self-training loop ---\n",
        "threshold = 0.05\n",
        "y_train_unlabeled_prev = None\n",
        "\n",
        "for i in range(1, 100):\n",
        "    y_train_unlabeled = classifier.predict(X_train_unlabeled_vec)\n",
        "    acc_unlabeled = accuracy_score(y_dummy, y_train_unlabeled)\n",
        "    print(f\"\\nIteration {i}: Accuracy on unlabeled (debug only): {100 * acc_unlabeled:.2f}%\")\n",
        "\n",
        "    if y_train_unlabeled_prev is not None:\n",
        "        label_change = 100 * (1 - accuracy_score(y_train_unlabeled, y_train_unlabeled_prev))\n",
        "        print(f\"Label change since last iteration: {label_change:.2f}%\\n\")\n",
        "        if accuracy_score(y_train_unlabeled, y_train_unlabeled_prev) > (1 - threshold):\n",
        "            print(\"Change below threshold, stopping self-training.\")\n",
        "            break\n",
        "\n",
        "    y_train_unlabeled_prev = y_train_unlabeled\n",
        "\n",
        "    # Combine labeled + pseudo-labeled data\n",
        "    X_combined = vstack([X_train_labeled_vec, X_train_unlabeled_vec])\n",
        "    y_combined = np.concatenate([y_train_labeled, y_train_unlabeled])\n",
        "\n",
        "    # Retrain model\n",
        "    classifier.fit(X_combined, y_combined)\n",
        "\n",
        "# --- Final Evaluation ---\n",
        "test_acc = 100 * accuracy_score(y_test, classifier.predict(X_test_vec))\n",
        "print(f\"\\nTesting:\\nAccuracy on test data: {test_acc:.2f}%\")\n"
      ]
    }
  ]
}