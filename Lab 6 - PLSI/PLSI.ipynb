{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijK6ttlZGfgb",
        "outputId": "8c2561ba-5f29-4831-af9c-5e7c2a368797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 300 documents from 3 categories.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256231190.py:71: RuntimeWarning: invalid value encountered in divide\n",
            "  P_z_d[d, :] /= P_z_d[d, :].sum()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/30 completed.\n",
            "Iteration 6/30 completed.\n",
            "Iteration 11/30 completed.\n",
            "Iteration 16/30 completed.\n",
            "Iteration 21/30 completed.\n",
            "Iteration 26/30 completed.\n",
            "Iteration 30/30 completed.\n",
            "\n",
            "âœ… PLSI training complete!\n",
            "\n",
            "Topic 1: space, tax, station, games, use, 000, 333, gun, just, russian\n",
            "Topic 2: space, edu, nasa, available, data, 02, information, colorado, won, 03\n",
            "Topic 3: think, don, just, people, good, like, know, year, work, time\n",
            "\n",
            "Documentâ€“Topic distribution (first 10 docs):\n",
            "\n",
            "   Topic 1  Topic 2  Topic 3\n",
            "0    0.000    1.000    0.000\n",
            "1    0.000    0.000    1.000\n",
            "2    0.010    0.000    0.990\n",
            "3    0.301    0.323    0.375\n",
            "4    0.631    0.000    0.369\n",
            "5    0.000    0.944    0.056\n",
            "6    1.000    0.000    0.000\n",
            "7    0.693    0.055    0.252\n",
            "8    0.715    0.285    0.000\n",
            "9    0.000    0.276    0.724\n"
          ]
        }
      ],
      "source": [
        "# ======================================================\n",
        "# ðŸ”¹ PROBABILISTIC LATENT SEMANTIC INDEXING (PLSI)\n",
        "#     using 20 Newsgroups dataset\n",
        "# ======================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load dataset\n",
        "# ---------------------------\n",
        "categories = ['rec.sport.baseball', 'sci.space', 'talk.politics.misc']\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories,\n",
        "                                remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "docs = newsgroups.data[:300]   # use 300 documents for speed\n",
        "print(f\"Loaded {len(docs)} documents from 3 categories.\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Create term-document matrix\n",
        "# ---------------------------\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X = vectorizer.fit_transform(docs).toarray()\n",
        "vocab = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "D, W = X.shape      # documents x words\n",
        "K = 3               # number of latent topics\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Initialize probabilities\n",
        "# ---------------------------\n",
        "np.random.seed(0)\n",
        "\n",
        "# P(w|z)\n",
        "P_w_z = np.random.rand(K, W)\n",
        "P_w_z /= P_w_z.sum(axis=1, keepdims=True)\n",
        "\n",
        "# P(z|d)\n",
        "P_z_d = np.random.rand(D, K)\n",
        "P_z_d /= P_z_d.sum(axis=1, keepdims=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. EM Algorithm\n",
        "# ---------------------------\n",
        "n_iter = 30\n",
        "for iteration in range(n_iter):\n",
        "    # --- E-step ---\n",
        "    P_z_dw = np.zeros((D, W, K))\n",
        "    for d in range(D):\n",
        "        for w in range(W):\n",
        "            prob = P_w_z[:, w] * P_z_d[d, :]\n",
        "            denom = prob.sum()\n",
        "            if denom > 0:\n",
        "                P_z_dw[d, w, :] = prob / denom\n",
        "\n",
        "    # --- M-step ---\n",
        "    # Update P(w|z)\n",
        "    for z in range(K):\n",
        "        for w in range(W):\n",
        "            P_w_z[z, w] = np.sum(X[:, w] * P_z_dw[:, w, z])\n",
        "        # Normalize\n",
        "        P_w_z[z, :] /= P_w_z[z, :].sum()\n",
        "\n",
        "    # Update P(z|d)\n",
        "    for d in range(D):\n",
        "        for z in range(K):\n",
        "            P_z_d[d, z] = np.sum(X[d, :] * P_z_dw[d, :, z])\n",
        "        # Normalize\n",
        "        P_z_d[d, :] /= P_z_d[d, :].sum()\n",
        "\n",
        "    if iteration % 5 == 0 or iteration == n_iter - 1:\n",
        "        print(f\"Iteration {iteration + 1}/{n_iter} completed.\")\n",
        "\n",
        "print(\"\\nâœ… PLSI training complete!\\n\")\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Display Top Words per Topic\n",
        "# ---------------------------\n",
        "n_top_words = 10\n",
        "for z in range(K):\n",
        "    top_idx = P_w_z[z, :].argsort()[-n_top_words:][::-1]\n",
        "    print(f\"Topic {z+1}: {', '.join(vocab[top_idx])}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Documentâ€“Topic Distribution\n",
        "# ---------------------------\n",
        "doc_topic_df = pd.DataFrame(P_z_d, columns=[f\"Topic {i+1}\" for i in range(K)])\n",
        "print(\"\\nDocumentâ€“Topic distribution (first 10 docs):\\n\")\n",
        "print(doc_topic_df.head(10).round(3))\n"
      ]
    }
  ]
}