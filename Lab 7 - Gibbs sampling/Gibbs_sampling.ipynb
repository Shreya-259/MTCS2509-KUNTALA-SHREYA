{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# FAST Joint Sentimentâ€“Topic Model (JST) using Gibbs Sampling\n",
        "# Optimized for Google Colab (100 topics)\n",
        "# ===============================================================\n",
        "\n",
        "!pip install datasets sentence-transformers scikit-learn numpy tqdm\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "import pickle\n",
        "\n",
        "# -------------------------\n",
        "# PARAMETERS\n",
        "# -------------------------\n",
        "K = 100               # topics\n",
        "S = 2                 # sentiments\n",
        "V = 3000\n",
        "MAX_DOCS = 1000\n",
        "DOC_MAX_WORDS = 100\n",
        "SEED = 42\n",
        "ITERATIONS = 100 # Define ITERATIONS here\n",
        "\n",
        "alpha_base = 0.1\n",
        "alpha_boost = 4.0\n",
        "beta = 0.01\n",
        "gamma = 0.1\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# -------------------------\n",
        "# TOKENIZER\n",
        "# -------------------------\n",
        "def tokenize(text):\n",
        "    return re.findall(r\"[a-zA-Z']+\", text.lower())\n",
        "\n",
        "# -------------------------\n",
        "# 1. Load Data\n",
        "# -------------------------\n",
        "print(\"Loading IMDB...\")\n",
        "dataset = load_dataset(\"imdb\", split=\"train\")\n",
        "if MAX_DOCS:\n",
        "    dataset = dataset.select(range(min(MAX_DOCS, len(dataset))))\n",
        "\n",
        "docs = [tokenize(x[\"text\"])[:DOC_MAX_WORDS] for x in dataset]\n",
        "\n",
        "# -------------------------\n",
        "# 2. Build Vocabulary\n",
        "# -------------------------\n",
        "print(\"Building vocabulary...\")\n",
        "from collections import Counter\n",
        "wc = Counter()\n",
        "for d in docs:\n",
        "    wc.update(d)\n",
        "\n",
        "vocab_words = [w for w, _ in wc.most_common(V)]\n",
        "vocab = {w:i for i,w in enumerate(vocab_words)}\n",
        "inv_vocab = {i:w for w,i in vocab.items()}\n",
        "\n",
        "UNK = V\n",
        "V_eff = V + 1\n",
        "\n",
        "docs_w = [[vocab[w] if w in vocab else UNK for w in d] for d in docs]\n",
        "D = len(docs_w)\n",
        "print(f\"Docs: {D}, Vocab size: {V_eff}\")\n",
        "\n",
        "# -------------------------\n",
        "# 3. Embeddings + Clustering\n",
        "# -------------------------\n",
        "print(\"Embedding documents...\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "emb = model.encode([\" \".join(d) for d in docs], batch_size=64)\n",
        "\n",
        "print(\"Clustering...\")\n",
        "kmeans = KMeans(n_clusters=K, n_init=10)\n",
        "cluster_id = kmeans.fit_predict(emb)\n",
        "\n",
        "# -------------------------\n",
        "# 4. Initialize Counts\n",
        "# -------------------------\n",
        "alpha_d = np.full((D, K), alpha_base)\n",
        "for d in range(D):\n",
        "    alpha_d[d, cluster_id[d]] += alpha_boost\n",
        "\n",
        "gamma_vec = np.full(S, gamma)\n",
        "\n",
        "n_d_s = np.zeros((D, S))\n",
        "n_d_s_z = np.zeros((D, S, K))\n",
        "n_s_z_w = np.zeros((S, K, V_eff))\n",
        "n_s_z = np.zeros((S, K))\n",
        "\n",
        "assign_s = []\n",
        "assign_z = []\n",
        "\n",
        "print(\"Random initialization...\")\n",
        "for d, wids in enumerate(docs_w):\n",
        "    As = []\n",
        "    Az = []\n",
        "    for w in wids:\n",
        "        s = np.random.randint(S)\n",
        "        z = np.random.randint(K)\n",
        "        As.append(s)\n",
        "        Az.append(z)\n",
        "        n_d_s[d, s] += 1\n",
        "        n_d_s_z[d, s, z] += 1\n",
        "        n_s_z_w[s, z, w] += 1\n",
        "        n_s_z[s, z] += 1\n",
        "    assign_s.append(As)\n",
        "    assign_z.append(Az)\n",
        "\n",
        "# -------------------------\n",
        "# 5. FAST GIBBS SAMPLING\n",
        "# -------------------------\n",
        "print(\"Starting FAST Gibbs Sampling...\")\n",
        "\n",
        "for it in range(ITERATIONS): # Use ITERATIONS here\n",
        "    for d in range(D):\n",
        "        for i, w in enumerate(docs_w[d]):\n",
        "\n",
        "            s_old = assign_s[d][i]\n",
        "            z_old = assign_z[d][i]\n",
        "\n",
        "            # remove old\n",
        "            n_d_s[d, s_old] -= 1\n",
        "            n_d_s_z[d, s_old, z_old] -= 1\n",
        "            n_s_z_w[s_old, z_old, w] -= 1\n",
        "            n_s_z[s_old, z_old] -= 1\n",
        "\n",
        "            # probability computation (vectorized)\n",
        "            probs_s = (n_d_s[d] + gamma_vec)  # shape (S)\n",
        "\n",
        "            probs = np.zeros((S, K))\n",
        "\n",
        "            for s in range(S):\n",
        "                term2 = n_d_s_z[d, s] + alpha_d[d]\n",
        "                term3 = (n_s_z_w[s, :, w] + beta) / (n_s_z[s] + V_eff*beta)\n",
        "                probs[s] = probs_s[s] * term2 * term3\n",
        "\n",
        "            flat = probs.ravel()\n",
        "            flat /= flat.sum()\n",
        "\n",
        "            idx = np.random.choice(S*K, p=flat)\n",
        "            s_new = idx // K\n",
        "            z_new = idx % K\n",
        "\n",
        "            assign_s[d][i] = s_new\n",
        "            assign_z[d][i] = z_new\n",
        "\n",
        "            n_d_s[d, s_new] += 1\n",
        "            n_d_s_z[d, s_new, z_new] += 1\n",
        "            n_s_z_w[s_new, z_new, w] += 1\n",
        "            n_s_z[s_new, z_new] += 1\n",
        "\n",
        "    if (it+1) % 10 == 0:\n",
        "        global_sent = (n_d_s.sum(axis=0) + 1e-9) / (n_d_s.sum() + 1e-9)\n",
        "        print(f\"Iter {it+1}/{ITERATIONS}: sentiment={global_sent}\") # Use ITERATIONS here\n",
        "\n",
        "print(\"Sampling complete.\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 6. Compute phi, etc.\n",
        "# -------------------------\n",
        "phi = (n_s_z_w + beta) / (n_s_z[:,:,None] + V_eff*beta)\n",
        "\n",
        "print(\"Top words in topic 0:\")\n",
        "top = phi[1,0].argsort()[-10:]\n",
        "print([inv_vocab.get(i,\"UNK\") for i in top])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKIRr3_8kTKE",
        "outputId": "1d7aef03-8392-4658-eb84-c3d21b33c3ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Loading IMDB...\n",
            "Building vocabulary...\n",
            "Docs: 1000, Vocab size: 3001\n",
            "Embedding documents...\n",
            "Clustering...\n",
            "Random initialization...\n",
            "Starting FAST Gibbs Sampling...\n",
            "Iter 10/100: sentiment=[0.50430673 0.49569327]\n",
            "Iter 20/100: sentiment=[0.50403789 0.49596211]\n",
            "Iter 30/100: sentiment=[0.50412061 0.49587939]\n",
            "Iter 40/100: sentiment=[0.50404823 0.49595177]\n",
            "Iter 50/100: sentiment=[0.50401721 0.49598279]\n",
            "Iter 60/100: sentiment=[0.50392414 0.49607586]\n",
            "Iter 70/100: sentiment=[0.50398619 0.49601381]\n",
            "Iter 80/100: sentiment=[0.5039655 0.4960345]\n",
            "Iter 90/100: sentiment=[0.50411027 0.49588973]\n",
            "Iter 100/100: sentiment=[0.50409993 0.49590007]\n",
            "Sampling complete.\n",
            "Top words in topic 0:\n",
            "['people', 'until', 'there', 'movies', 'great', 'only', 'watching', 'thing', 'like', \"it's\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top words in topic 0:\")\n",
        "top = phi[0,1].argsort()[-10:]\n",
        "print([inv_vocab.get(i,\"UNK\") for i in top])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfKU8e44n3u-",
        "outputId": "8587f709-bb56-477e-8a76-2b157883a34a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top words in topic 0:\n",
            "['them', 'shows', 'like', 'completely', 'stupid', 'goes', 'is', 'that', 'with', 'are']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_N = 10\n",
        "\n",
        "for z in range(100):\n",
        "    print(f\"\\nTopic {z}:\")\n",
        "    print(\"  Negative:\", [inv_vocab.get(i,\"UNK\") for i in phi[0,z].argsort()[-TOP_N:]])\n",
        "    print(\"  Positive:\", [inv_vocab.get(i,\"UNK\") for i in phi[1,z].argsort()[-TOP_N:]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmE-nhZOn6zx",
        "outputId": "70583a01-07e5-42aa-9203-9d1c6e489168"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic 0:\n",
            "  Negative: ['life', 'is', 'then', 'of', 'the', 'by', 'her', 'and', 'in', 'UNK']\n",
            "  Positive: ['people', 'until', 'there', 'movies', 'great', 'only', 'watching', 'thing', 'like', \"it's\"]\n",
            "\n",
            "Topic 1:\n",
            "  Negative: ['them', 'shows', 'like', 'completely', 'stupid', 'goes', 'is', 'that', 'with', 'are']\n",
            "  Positive: ['close', 'getting', 'from', 'out', 'comes', 'one', 'by', 'but', 'it', 'not']\n",
            "\n",
            "Topic 2:\n",
            "  Negative: ['but', 'from', 'than', 'good', 'like', 'more', 'UNK', 'to', 'the', 'it']\n",
            "  Positive: ['story', 'for', \"it's\", 'in', 'not', 'that', 'and', 'a', 'is', 'the']\n",
            "\n",
            "Topic 3:\n",
            "  Negative: [\"it's\", 'for', 'with', 'see', 'if', 'this', 'you', 'to', 'and', 'UNK']\n",
            "  Positive: ['science', 'fiction', 'yet', 'time', 'when', \"it's\", 'about', 'that', 'is', 'the']\n",
            "\n",
            "Topic 4:\n",
            "  Negative: ['york', 'two', 'life', 'was', 'his', 'new', 'very', 'the', 'UNK', 'in']\n",
            "  Positive: ['dialogue', 'seems', 'off', 'old', 'both', 'around', 'an', 'on', 'and', 'UNK']\n",
            "\n",
            "Topic 5:\n",
            "  Negative: ['working', 'however', 'more', 'known', 'who', 'about', 'br', 'of', 'a', 'UNK']\n",
            "  Positive: ['get', 'bring', 'taken', 'looking', 'off', 'back', 'for', 'by', 'to', 'and']\n",
            "\n",
            "Topic 6:\n",
            "  Negative: ['which', 'us', 'and', 'has', 'was', 'by', 'film', 'in', 'a', 'UNK']\n",
            "  Positive: ['throughout', 'la', 'subject', 'where', 'world', 'on', 'from', 'of', 'a', 'UNK']\n",
            "\n",
            "Topic 7:\n",
            "  Negative: ['many', 'it', 'french', 'fall', 'love', 'all', 'also', 'a', 'city', 'its']\n",
            "  Positive: ['characters', 'take', 'garbage', 'just', 'at', 'some', 'up', 'that', 'can', 'br']\n",
            "\n",
            "Topic 8:\n",
            "  Negative: ['would', 'what', 'going', 'well', 'be', 'on', 'that', 'it', 'i', 'to']\n",
            "  Positive: ['cinema', 'be', 'they', 'this', 'we', 'films', 'of', 'film', 'the', 'UNK']\n",
            "\n",
            "Topic 9:\n",
            "  Negative: ['dull', 'rather', 'seen', 'have', 'feature', 'beyond', 'over', 'and', 'the', 'UNK']\n",
            "  Positive: ['come', 'better', \"it's\", 'stories', 'think', 'for', 'get', 'it', 'would', 'because']\n",
            "\n",
            "Topic 10:\n",
            "  Negative: ['excellent', 'turns', 'kind', 'cast', 'then', 'in', 'time', 'as', 'the', 'UNK']\n",
            "  Positive: ['down', 'over', 'fit', 'something', 'big', 'people', 'just', 'is', 'this', 'a']\n",
            "\n",
            "Topic 11:\n",
            "  Negative: ['any', 'how', 'names', 'is', 'wrong', 'movies', 'big', 'this', 'the', 'i']\n",
            "  Positive: ['all', 'a', \"can't\", 'just', 'with', 'make', 'so', 'and', 'they', 'to']\n",
            "\n",
            "Topic 12:\n",
            "  Negative: ['though', 'as', 'character', 'that', 'given', 'film', 'and', 'UNK', 'the', 'of']\n",
            "  Positive: ['small', 'second', 'both', 'play', 'first', 'there', 'own', 'his', 'not', 'as']\n",
            "\n",
            "Topic 13:\n",
            "  Negative: ['up', 'having', 'they', 'has', \"it's\", 'for', 'are', 'in', 'the', 'UNK']\n",
            "  Positive: ['get', 'out', 'bill', 'title', 'story', 'be', 'just', 'little', 'one', 'UNK']\n",
            "\n",
            "Topic 14:\n",
            "  Negative: ['actually', 'up', 'thing', 'been', 'just', 'be', 'have', 'UNK', 'all', 'that']\n",
            "  Positive: ['show', 'with', 'off', 'life', 'for', 'that', 'and', 'she', 'to', 'her']\n",
            "\n",
            "Topic 15:\n",
            "  Negative: ['hollywood', 'making', 'an', 'both', 'they', 'my', 'movie', 'are', 'not', 'in']\n",
            "  Positive: ['all', 'beginning', 'like', 'if', 'i', 'very', 'good', 'to', 'and', 'the']\n",
            "\n",
            "Topic 16:\n",
            "  Negative: ['after', 'killer', 'performances', 'get', 'one', 'an', 'br', 'of', 'the', 'UNK']\n",
            "  Positive: ['bit', 'girls', 'original', 'group', 'his', 'think', 'killer', 'of', 'the', 'a']\n",
            "\n",
            "Topic 17:\n",
            "  Negative: [\"doesn't\", 'your', 'but', 'pretty', 'one', 'just', 'with', 'this', 'you', 'is']\n",
            "  Positive: ['only', 'plot', 'horror', 'on', 'movie', 'is', 'in', 'UNK', 'a', 'the']\n",
            "\n",
            "Topic 18:\n",
            "  Negative: ['not', 'and', 'there', 'are', 'a', 'if', 'you', 'in', 'the', 'UNK']\n",
            "  Positive: ['made', 'plot', 'had', 'people', 'what', 'film', 'is', 'UNK', 'of', 'the']\n",
            "\n",
            "Topic 19:\n",
            "  Negative: ['know', \"it's\", \"isn't\", 'off', 'you', 'in', 'one', 'is', 'first', 'a']\n",
            "  Positive: ['been', 'slasher', 'least', 'well', 'no', 'all', 'not', 'and', 'so', 'is']\n",
            "\n",
            "Topic 20:\n",
            "  Negative: ['because', 'from', 'plot', 'a', 'UNK', 'film', 'in', 'of', 'is', 'br']\n",
            "  Positive: ['an', 'or', 'but', \"don't\", 'than', 'with', 'a', 'movie', 'and', 'UNK']\n",
            "\n",
            "Topic 21:\n",
            "  Negative: ['when', 'after', 'horror', 'but', 'this', 'and', 'it', 'was', 'the', 'i']\n",
            "  Positive: ['me', 'horror', 'about', 'movie', 'you', 'to', 'of', 'this', 'a', 'the']\n",
            "\n",
            "Topic 22:\n",
            "  Negative: ['how', 'has', 'through', 'long', 'so', 'be', 'movie', 'this', 'not', 'to']\n",
            "  Positive: ['there', 'idea', 'with', 'ever', 'their', 'like', 'were', 'no', 'at', 'and']\n",
            "\n",
            "Topic 23:\n",
            "  Negative: ['star', 'say', 'episode', 'series', 'to', 'all', 'first', 'i', 'an', 'of']\n",
            "  Positive: ['straight', 'hollywood', 'probably', 'during', 'quality', 'could', 'do', 'them', 'one', 'br']\n",
            "\n",
            "Topic 24:\n",
            "  Negative: ['of', 'which', 'who', 'the', 'his', 'as', 'to', 'he', 'a', 'is']\n",
            "  Positive: ['turn', 'younger', 'tone', 'black', 'girl', 'now', 'in', 'watching', 'young', 'UNK']\n",
            "\n",
            "Topic 25:\n",
            "  Negative: ['do', 'can', 'we', 'if', 'are', 'they', 'show', 'and', 'the', 'UNK']\n",
            "  Positive: ['keep', 'are', 'book', 'of', 'about', 'but', 'in', 'is', 'UNK', 'the']\n",
            "\n",
            "Topic 26:\n",
            "  Negative: ['be', 'but', 'who', 'man', 'i', 'to', 'out', 'it', 'UNK', 'a']\n",
            "  Positive: ['two', 'at', 'are', 'in', 'a', 'is', 'of', 'br', 'UNK', 'the']\n",
            "\n",
            "Topic 27:\n",
            "  Negative: ['them', 'say', 'than', 'this', 'is', 'may', 'girl', 'with', 'so', 'br']\n",
            "  Positive: ['women', 'have', 'spoilers', 'than', 'other', 'out', 'with', 'as', 'br', 'UNK']\n",
            "\n",
            "Topic 28:\n",
            "  Negative: ['spacey', 'timberlake', 'morgan', 'justin', 'kevin', 'freeman', 'big', 'about', 'which', 'a']\n",
            "  Positive: ['before', 'but', 'movie', 'guy', 'top', 'shot', 'over', 'he', 'bad', 'the']\n",
            "\n",
            "Topic 29:\n",
            "  Negative: ['script', 'to', 'a', 'has', 'film', 'of', 'this', 'and', 'the', 'UNK']\n",
            "  Positive: ['not', 'in', 'to', 'and', 'this', 'it', 'the', 'was', 'movie', 'i']\n",
            "\n",
            "Topic 30:\n",
            "  Negative: ['brought', 'j', 'from', 'another', 'opening', 'have', 'when', 'as', 'after', 'UNK']\n",
            "  Positive: ['off', 'with', 'review', 'may', 'from', 'boring', 'some', 'people', 'the', 'a']\n",
            "\n",
            "Topic 31:\n",
            "  Negative: ['role', 'made', 'tv', 'should', 'director', 'peter', 'for', 'as', 'a', 'UNK']\n",
            "  Positive: ['where', 'movies', 'cast', 'much', 'last', 'into', 'UNK', 'is', 'as', 'the']\n",
            "\n",
            "Topic 32:\n",
            "  Negative: ['actress', 'every', 'be', 'there', 'woman', 'an', 'she', 'or', 'with', 'to']\n",
            "  Positive: [\"you're\", 'over', 'an', 'into', 'film', 'in', 'and', 'of', 'a', 'UNK']\n",
            "\n",
            "Topic 33:\n",
            "  Negative: ['funny', 'like', 'sandler', 'only', 'movie', 'to', 'this', 'was', 'i', 'it']\n",
            "  Positive: ['every', 'line', 'other', 'for', 'makes', 'all', 'at', 'actors', 'this', 'movie']\n",
            "\n",
            "Topic 34:\n",
            "  Negative: ['picture', 'have', 'last', 'two', 'up', 'love', 'with', 'such', 'the', 'that']\n",
            "  Positive: ['action', 'up', 'at', 'movies', 'about', 'they', 'we', 'kid', 'for', 'no']\n",
            "\n",
            "Topic 35:\n",
            "  Negative: ['premise', 'valentine', 'too', 'absolutely', 'nothing', 'movies', 'there', 'are', 'that', 'movie']\n",
            "  Positive: ['anything', 'know', 'in', \"that's\", 'it', 'they', 'what', 'movie', 'not', 'br']\n",
            "\n",
            "Topic 36:\n",
            "  Negative: ['can', 'so', \"it's\", 'be', \"didn't\", 'and', 'movie', 'a', 'in', 'UNK']\n",
            "  Positive: ['made', 'scenes', 'can', 'thing', 'but', 'through', 'have', 'it', 'of', 'a']\n",
            "\n",
            "Topic 37:\n",
            "  Negative: ['through', 'there', 'out', 'up', 'when', 'of', 'is', 'plot', 'film', 'the']\n",
            "  Positive: ['one', 'this', 'things', 'few', 'which', 'so', 'and', 'is', 'of', 'the']\n",
            "\n",
            "Topic 38:\n",
            "  Negative: ['kelly', 'from', 'unfortunately', 'jim', 'ned', 'has', 'same', 'check', 'and', 'the']\n",
            "  Positive: ['about', 'rather', 'than', 'trying', 'are', 'character', 'when', 'good', 'in', 'as']\n",
            "\n",
            "Topic 39:\n",
            "  Negative: ['moments', 'have', 'best', 'another', 'at', 'much', 'to', 'from', 'is', 'too']\n",
            "  Positive: ['reality', 'decent', 'couple', 'live', \"i've\", 'more', 'from', 'for', 'new', 'show']\n",
            "\n",
            "Topic 40:\n",
            "  Negative: ['bored', 'decided', 'get', 'columbo', 'thinking', 'time', 'UNK', 'out', 'no', 'this']\n",
            "  Positive: ['teacher', 'amount', 'its', 'columbo', 'example', 'average', 'becomes', 'of', 'a', 'UNK']\n",
            "\n",
            "Topic 41:\n",
            "  Negative: ['things', 'way', 'man', 'only', 'such', 'what', 'one', 'other', 'be', 'for']\n",
            "  Positive: ['later', 'indian', 'father', 'mother', 'friends', 'years', 'their', 'in', 'to', 'UNK']\n",
            "\n",
            "Topic 42:\n",
            "  Negative: ['nice', 'completely', 'sense', 'takes', 'into', 'more', 'fact', 'one', \"it's\", 'a']\n",
            "  Positive: ['came', 'tmnt', 'someone', 'original', 'all', 'more', 'better', 'series', 'back', 'was']\n",
            "\n",
            "Topic 43:\n",
            "  Negative: ['bunch', 'looking', 'called', 'you', 'great', 'make', 'their', 'some', 'on', 'and']\n",
            "  Positive: ['blank', 'be', 'been', \"i've\", 'fact', 'check', 'have', 'good', 'on', 'a']\n",
            "\n",
            "Topic 44:\n",
            "  Negative: ['how', 'really', 'one', \"wasn't\", 'everything', 'this', 'movie', 'some', 'but', 'in']\n",
            "  Positive: ['vampire', 'when', 'an', 'here', 'with', 'is', 'performance', 'his', 'he', 'UNK']\n",
            "\n",
            "Topic 45:\n",
            "  Negative: ['group', 'anyone', 'shot', 'those', 'right', 'young', 'their', 'the', 'of', 'UNK']\n",
            "  Positive: ['dies', 'then', 'right', 'director', 'scarecrow', 'gets', 'by', 'some', 'the', 'UNK']\n",
            "\n",
            "Topic 46:\n",
            "  Negative: ['are', 'is', 'better', 'even', 'acting', 'it', 'bad', 'movie', 'this', 'the']\n",
            "  Positive: ['than', 'even', 'script', 'of', 'this', 'are', 'bad', 'it', 'the', 'is']\n",
            "\n",
            "Topic 47:\n",
            "  Negative: ['any', 'characters', 'with', 'fun', 'prom', 'to', 'night', 'by', 'being', 'and']\n",
            "  Positive: ['suspense', 'script', 'prom', 'again', 'out', 'see', 'night', 'its', 'it', 'that']\n",
            "\n",
            "Topic 48:\n",
            "  Negative: ['must', 'simply', 'very', 'disappointed', 'would', 'in', 'be', 'is', 'for', 'but']\n",
            "  Positive: ['no', 'just', 'would', 'to', 'this', 'a', 'movie', 'was', 'i', 'it']\n",
            "\n",
            "Topic 49:\n",
            "  Negative: ['which', 'saw', 'it', 'movies', 'do', 'on', 'really', 'no', 'i', 'this']\n",
            "  Positive: ['seemed', 'good', 'actually', 'ending', 'done', 'several', 'been', 'they', 'here', 'it']\n",
            "\n",
            "Topic 50:\n",
            "  Negative: ['when', 'real', 'then', 'over', \"doesn't\", 'before', 'it', 'show', 'and', 'UNK']\n",
            "  Positive: ['watched', 'already', 'nothing', 'know', 'am', 'up', 'with', 'to', 'i', 'UNK']\n",
            "\n",
            "Topic 51:\n",
            "  Negative: ['where', 'away', 'your', 'will', 'pretty', 'time', 'some', 'his', 'him', 'he']\n",
            "  Positive: ['good', 'like', 'of', 'way', 'which', 'from', 'who', 'to', 'the', 'UNK']\n",
            "\n",
            "Topic 52:\n",
            "  Negative: ['while', 'bit', 'considering', 'give', 'between', 'me', 'on', 'little', 'that', 'UNK']\n",
            "  Positive: ['better', 'doing', 'chronicles', 'd', 'by', 'zombie', 'who', 'to', 'a', 'UNK']\n",
            "\n",
            "Topic 53:\n",
            "  Negative: ['find', 'could', 'scenes', 'no', 'is', 'or', 'not', 'with', 'the', 'in']\n",
            "  Positive: ['point', \"aren't\", 'side', 'kind', 'together', 'as', 'scene', 'director', 'one', 'with']\n",
            "\n",
            "Topic 54:\n",
            "  Negative: ['last', 'me', 'see', 'so', 'her', 'of', 'was', 'in', 'and', 'UNK']\n",
            "  Positive: ['say', 'murphy', 'child', 'an', 'that', 'all', 'lot', 'a', 'and', 'UNK']\n",
            "\n",
            "Topic 55:\n",
            "  Negative: ['me', 'where', 'well', 'back', 'time', 'who', 'of', 'from', 'a', 'UNK']\n",
            "  Positive: [\"don't\", 'do', 'to', 'pretty', 'be', 'has', 'what', 'in', 'movie', 'this']\n",
            "\n",
            "Topic 56:\n",
            "  Negative: ['couple', 'makes', 'left', 'at', 'awful', 'UNK', 'but', 'to', 'and', 'is']\n",
            "  Positive: ['between', 'when', 'other', 'after', 'two', 'love', 'are', 'is', 'UNK', 'and']\n",
            "\n",
            "Topic 57:\n",
            "  Negative: ['often', 'something', 'act', 'up', 'list', 'start', 'kids', 'films', 'of', 'the']\n",
            "  Positive: ['evil', 'guy', 'death', 'has', 'money', 'into', 'him', 'who', 'he', 'his']\n",
            "\n",
            "Topic 58:\n",
            "  Negative: ['my', 'for', 'seen', 'a', 'movie', 'the', 'this', 'to', 'of', 'i']\n",
            "  Positive: ['say', 'a', 'it', 'on', 'for', 'i', 'this', 'that', 'to', 'UNK']\n",
            "\n",
            "Topic 59:\n",
            "  Negative: ['all', 'does', 'been', 'book', 'have', 'that', 'and', 'is', 'of', 'the']\n",
            "  Positive: ['early', 'after', 'three', 'two', 'american', 'quite', 'life', 'to', 'was', 'in']\n",
            "\n",
            "Topic 60:\n",
            "  Negative: ['beginning', 'into', 'will', 'young', 'end', 'story', 'for', 'and', 'up', 'br']\n",
            "  Positive: ['this', 'then', 'some', 'really', 'but', 'the', 'with', 'of', 'very', 'and']\n",
            "\n",
            "Topic 61:\n",
            "  Negative: ['own', 'guess', 'earth', \"don't\", 'me', 'make', 'but', 'is', 'about', 'br']\n",
            "  Positive: ['watching', 'timon', 'before', 'story', 'an', 'was', 'just', 'me', 'and', 'UNK']\n",
            "\n",
            "Topic 62:\n",
            "  Negative: ['scene', 'people', 'with', 'there', 'know', 'other', 'we', 'so', 'that', 'movie']\n",
            "  Positive: ['is', 'or', 'much', 'after', 'see', 'only', 'story', 'but', 'of', 'the']\n",
            "\n",
            "Topic 63:\n",
            "  Negative: ['these', 'because', 'love', 'great', 'by', 'so', 'be', 'cast', 'the', 'to']\n",
            "  Positive: ['great', 'for', 'from', 'too', 'had', 'most', 'this', 'that', 'as', 'UNK']\n",
            "\n",
            "Topic 64:\n",
            "  Negative: ['same', 'well', 'thing', 'only', 'most', 'about', 'they', 'are', 'of', 'as']\n",
            "  Positive: ['watched', 'for', 'be', 'must', 'original', 'to', 'it', 'were', 'still', 'the']\n",
            "\n",
            "Topic 65:\n",
            "  Negative: ['film', 'different', 'these', 'story', 'them', 'been', 'had', 'the', 'and', 'was']\n",
            "  Positive: ['might', 'something', 'much', 'they', 'have', 'tv', 'i', 's', 'so', 'a']\n",
            "\n",
            "Topic 66:\n",
            "  Negative: ['almost', 'would', 'got', 'good', 'without', 'ending', 'plot', 'scenes', 'bad', 'was']\n",
            "  Positive: ['of', 'less', 'imagine', 'can', 'one', 'is', 'because', 'has', 'you', 'and']\n",
            "\n",
            "Topic 67:\n",
            "  Negative: ['played', 'did', 'performance', 'good', 'i', 'at', 'who', 'what', 'and', 'was']\n",
            "  Positive: ['done', \"i'm\", \"didn't\", 'story', 'i', 'have', 'much', 'all', 'at', 'was']\n",
            "\n",
            "Topic 68:\n",
            "  Negative: ['cannibal', 'buchfellner', 'looking', 'laura', 'video', 'jungle', 'around', 'on', 'by', 'to']\n",
            "  Positive: ['body', 'away', 'mind', 'first', 'one', 'while', 'will', 'a', 'of', 'the']\n",
            "\n",
            "Topic 69:\n",
            "  Negative: ['few', 'ever', 'quality', 'as', 'thought', 'would', 'way', 'on', 'all', 'very']\n",
            "  Positive: ['women', 'any', 'others', 'their', 'bad', 'films', 'were', 'so', 'or', 'that']\n",
            "\n",
            "Topic 70:\n",
            "  Negative: ['jack', 'king', 'it', 'two', 'and', 'movie', 'a', 'out', 'with', 'UNK']\n",
            "  Positive: ['be', 'funny', 'camera', 'your', 'want', \"don't\", 'well', 'it', 'if', 'you']\n",
            "\n",
            "Topic 71:\n",
            "  Negative: ['work', 'either', 'original', 'much', 'think', 'found', 'acting', 'for', 'this', 'or']\n",
            "  Positive: ['the', 'through', 'has', 'from', 'set', 'go', 'high', 'way', 'who', 'had']\n",
            "\n",
            "Topic 72:\n",
            "  Negative: ['sort', 'characters', 'of', \"there's\", 'here', 'your', 'never', 'predictable', 'then', 'on']\n",
            "  Positive: ['those', 'only', 'man', 'up', 'from', 'a', 'by', 'would', 'be', 'to']\n",
            "\n",
            "Topic 73:\n",
            "  Negative: ['system', 'is', 'women', 'how', 'want', 'supposed', 'they', 'about', 'what', 'the']\n",
            "  Positive: ['themselves', 'hours', 'buy', 'possible', 'kids', 'my', 'even', \"i'd\", 'for', 'money']\n",
            "\n",
            "Topic 74:\n",
            "  Negative: ['disappointing', 'their', 'anyone', 'or', 'character', 'one', 'she', 'a', 'her', 'UNK']\n",
            "  Positive: ['all', 'more', 'many', 'me', 'had', 'only', 'i', 'this', 'movie', 'to']\n",
            "\n",
            "Topic 75:\n",
            "  Negative: ['almost', 'bad', 'there', 'boring', 'plain', \"that's\", 'plot', 'or', 'just', 'UNK']\n",
            "  Positive: ['scenes', 'were', 'however', 'with', 'had', 'which', 'there', 'of', 'UNK', 'and']\n",
            "\n",
            "Topic 76:\n",
            "  Negative: ['until', 'if', 'hours', 'acting', 'come', 'ever', 'for', 'never', 'terrible', 'the']\n",
            "  Positive: ['kind', 'many', 'like', 'this', 'new', 'up', 'with', \"it's\", 'that', 'UNK']\n",
            "\n",
            "Topic 77:\n",
            "  Negative: ['years', \"don't\", 'might', 'better', 'down', 'two', 'did', 'and', 'to', 'the']\n",
            "  Positive: ['almost', 'reason', 'hour', 'we', 'same', 'seen', 'so', 'have', 'why', 'this']\n",
            "\n",
            "Topic 78:\n",
            "  Negative: ['has', 'she', 'when', 'at', 'her', 'only', 'is', 'a', 'UNK', 'the']\n",
            "  Positive: ['moments', 'those', 'believe', 'cast', 'made', 'be', 'any', 'is', 'to', 'that']\n",
            "\n",
            "Topic 79:\n",
            "  Negative: ['years', 'world', 'face', 'us', 'and', 'part', 'minutes', 'most', 'of', 'the']\n",
            "  Positive: ['find', 'best', 'sound', 'story', 'acting', 'of', 'in', 'be', 'the', 'UNK']\n",
            "\n",
            "Topic 80:\n",
            "  Negative: ['definitely', 'playing', 'which', 'question', 'still', 'big', 'who', 's', 'as', 'UNK']\n",
            "  Positive: [\"it's\", 'computer', 'also', 'an', 'virus', 'be', 'though', 'about', 'that', 'UNK']\n",
            "\n",
            "Topic 81:\n",
            "  Negative: ['believe', 'problem', 'can', 'with', 'an', 'when', 'he', 'mother', 'his', 'and']\n",
            "  Positive: ['watched', 'guy', 'at', 'time', 'watch', 'like', \"didn't\", 'but', 'my', 'i']\n",
            "\n",
            "Topic 82:\n",
            "  Negative: ['tells', 'love', 'something', 'his', 'him', \"he's\", 'a', 'for', 'to', 'UNK']\n",
            "  Positive: ['saw', \"wasn't\", 'when', 'actually', 'end', 'by', 'bad', 'that', 'was', 'the']\n",
            "\n",
            "Topic 83:\n",
            "  Negative: ['seriously', 'characters', 'much', 'first', 'way', 'watching', 'but', 'they', 'were', 'the']\n",
            "  Positive: ['idea', 'paul', 'some', 'man', 'even', 'have', 'story', 'it', 'to', 'a']\n",
            "\n",
            "Topic 84:\n",
            "  Negative: ['it', 'okay', 'times', 'not', 'movie', 'who', 'guy', 'funny', 'i', 'a']\n",
            "  Positive: ['work', 'these', 'get', \"doesn't\", 'another', 'for', 'or', 'a', 'all', 'to']\n",
            "\n",
            "Topic 85:\n",
            "  Negative: ['female', 'david', 'was', 'oscar', 'material', 'their', 'go', 'not', 'an', 'UNK']\n",
            "  Positive: ['not', 'movies', 'going', 'awful', 'acting', 'be', 'watch', 'would', 'i', 'my']\n",
            "\n",
            "Topic 86:\n",
            "  Negative: ['yet', 'some', 'movie', 'other', 'way', 'the', 'and', 'one', 'of', 'in']\n",
            "  Positive: ['has', 'but', 'with', 'job', 'best', 'more', 'his', 'should', 'does', 'in']\n",
            "\n",
            "Topic 87:\n",
            "  Negative: ['get', 'there', 'something', 'film', 'were', 'nothing', 'just', 'this', 'to', 'was']\n",
            "  Positive: ['anyone', 'expect', 'get', 'say', 'love', 'on', 'and', 'you', 'to', 'UNK']\n",
            "\n",
            "Topic 88:\n",
            "  Negative: ['so', 'would', 'this', 'think', 'for', 'at', 'just', 'the', 'i', 'br']\n",
            "  Positive: ['first', 'read', 'which', 'time', 'has', 'in', 'and', 'i', 'br', 'the']\n",
            "\n",
            "Topic 89:\n",
            "  Negative: ['know', 'good', 'can', 'saw', 'my', 'he', 'no', 'have', 'a', 'i']\n",
            "  Positive: ['UNK', 'and', 'of', 'a', 'film', 'in', 'was', 'this', 'the', 'br']\n",
            "\n",
            "Topic 90:\n",
            "  Negative: ['barely', 'add', 'what', 'set', 'trying', 'old', 'also', \"i'm\", 'it', 'a']\n",
            "  Positive: ['your', 'being', 'actors', 'as', 'feel', 'will', 'many', 'you', 'this', 'film']\n",
            "\n",
            "Topic 91:\n",
            "  Negative: ['thing', 'money', 'by', 'low', 'budget', 'some', 'of', 'a', 'and', 'UNK']\n",
            "  Positive: ['reviewers', 'theme', 'police', 'take', 'as', 'in', 'on', 'that', 'and', 'UNK']\n",
            "\n",
            "Topic 92:\n",
            "  Negative: ['white', 'took', 'complete', 'their', 'plays', 'with', 'black', 'at', 'and', 'UNK']\n",
            "  Positive: ['nor', 'just', 'most', \"'\", 'it', 'never', 'or', 'UNK', 'of', 'the']\n",
            "\n",
            "Topic 93:\n",
            "  Negative: ['same', 'apparently', 'by', 'sexual', 'sex', 'film', 'for', 'and', 'on', 'UNK']\n",
            "  Positive: ['sometimes', 'totally', 'sounds', 'despite', 'what', 'for', 'interesting', 'funny', 'not', 'the']\n",
            "\n",
            "Topic 94:\n",
            "  Negative: ['plot', 'really', 'story', 'acting', 'but', 'not', 'good', 'to', 'it', 'is']\n",
            "  Positive: ['worst', 'not', 'how', 'every', 'really', 'been', 'like', 'could', 'i', 'have']\n",
            "\n",
            "Topic 95:\n",
            "  Negative: [\"don't\", 'clich', 'this', 'sure', 'one', 'who', 'films', 'bad', 'film', 'like']\n",
            "  Positive: ['big', 'waste', 'a', 'stupid', 'film', 'too', 'for', 'are', 'time', 'is']\n",
            "\n",
            "Topic 96:\n",
            "  Negative: ['like', 'interesting', 'now', 'made', 'film', 'are', 'effects', 'special', 'not', 'the']\n",
            "  Positive: ['told', 'without', 'could', 'true', 'the', 'special', 'this', 'effects', 'as', 'of']\n",
            "\n",
            "Topic 97:\n",
            "  Negative: ['early', 'directors', 'least', 'years', 'would', 'reason', 'high', 'was', 'that', 'this']\n",
            "  Positive: ['good', 'ever', 'worst', 'saw', 'when', 'be', 'thought', 'one', 'it', 'i']\n",
            "\n",
            "Topic 98:\n",
            "  Negative: ['because', 'as', 'so', 'been', 'at', 'was', 'see', 'of', 'have', 'it']\n",
            "  Positive: ['however', 'seemed', 'everything', 'of', 'really', 'with', 'no', 'is', 'but', 'film']\n",
            "\n",
            "Topic 99:\n",
            "  Negative: ['film', 'huge', 'adam', 'because', \"couldn't\", 'get', 'fan', 'on', 'there', 'a']\n",
            "  Positive: ['from', 'hackman', 'performances', 'be', 'up', 'minutes', 'their', 'in', 'by', 'and']\n"
          ]
        }
      ]
    }
  ]
}